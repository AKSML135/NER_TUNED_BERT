{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012c72012d7d428a9d96e35bdad3beb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ace093a656224d209a75e8e126812ed4",
              "IPY_MODEL_6e821c90f70c4e35902db950cb5ed1dd",
              "IPY_MODEL_2ccebf7f3f9f47ac9ae5c3f34a744452"
            ],
            "layout": "IPY_MODEL_8ad9b8165a9c4bb4b40f1750d3a61988"
          }
        },
        "ace093a656224d209a75e8e126812ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf813c991684d4ca6a24e4a8a926915",
            "placeholder": "​",
            "style": "IPY_MODEL_5273f8f00525430d83adefbc8e06a803",
            "value": "Downloading builder script: "
          }
        },
        "6e821c90f70c4e35902db950cb5ed1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0738ae560eb649a8b6ee0eca18b1325e",
            "max": 2472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beeeb85fd68348f593831c1d7636f382",
            "value": 2472
          }
        },
        "2ccebf7f3f9f47ac9ae5c3f34a744452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b617ce3fd00e45fd9c8a900840251ed8",
            "placeholder": "​",
            "style": "IPY_MODEL_b0eda20b8f554d6d9563f08f3428aa88",
            "value": " 6.33k/? [00:00&lt;00:00, 167kB/s]"
          }
        },
        "8ad9b8165a9c4bb4b40f1750d3a61988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf813c991684d4ca6a24e4a8a926915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5273f8f00525430d83adefbc8e06a803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0738ae560eb649a8b6ee0eca18b1325e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beeeb85fd68348f593831c1d7636f382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b617ce3fd00e45fd9c8a900840251ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0eda20b8f554d6d9563f08f3428aa88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tokenizers seqeval -q"
      ],
      "metadata": {
        "id": "_BQXe0wnYIud"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "og7VtdOcYRhZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/learn/nlp-course/chapter7/2\n"
      ],
      "metadata": {
        "id": "Vj907Spjzy0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.load_dataset('conll2003')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQx6sVftY_gF",
        "outputId": "8d7e2274-e294-46d1-8a49-df805453d515"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MouhNXIHZINr",
        "outputId": "49075428-9a6a-42f4-a271-f96d58cdf19e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESZEn4IiZawj",
        "outputId": "51f51b55-7a77-4f61-97d3-8b13f388b2c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features['ner_tags']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm5zwzhTZovj",
        "outputId": "88cf256d-b95a-431d-fbc9-4b3c894a30a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- O means the word doesn’t correspond to any entity.\n",
        "- B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
        "- B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
        "- B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
        "- B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity."
      ],
      "metadata": {
        "id": "_MeuMxHU0Plm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "PKOAbMGpaEva"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem of consecutive subwords.**\n",
        "\n",
        "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer.\n",
        "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain.\n",
        "This is happening, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens:\n",
        "\n",
        "**Strategy to handle above -**\n",
        "\n",
        "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:\n",
        "Setting –100 as the label for these special tokens and the subwords we wish to mask during training:\n",
        "Why did we choose –100 as the ID to mask subword representations? The reason is that in PyTorch the cross-entropy loss class torch.nn.CrossEntropyLoss has an attribute called ignore_index whose value is –100. This index is ignored during training,\n",
        "\n",
        "Also we can use it to ignore the tokens associated with consecutive subwords."
      ],
      "metadata": {
        "id": "CGVWO-wW0fzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = data['train'][0]\n",
        "example_text['tokens']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7gGD6i0afry",
        "outputId": "db4d6f74-ca84-486c-aa21-986638679be8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input = tokenizer(example_text['tokens'], is_split_into_words=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])"
      ],
      "metadata": {
        "id": "rZGmVulAbz7R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-SiMfmqcI5K",
        "outputId": "9ffa8b2e-0232-405d-8c13-5e833dbe8c81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'eu',\n",
              " 'rejects',\n",
              " 'german',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'british',\n",
              " 'lamb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[CLS]** means the start of a sentence and **[SEP]** makes BERT know the second sentence has begun. At finetuning time, if you use a different format than pretraining format, you might confuse the model : he never saw 2 sentences formatted as [CLS] Sen A Sen B [SEP]. The model doesn't know there is 2 sentences, and will consider it as a single sentence."
      ],
      "metadata": {
        "id": "0d2PaLHZcr0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " tokenized_input.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyQ1SgxEdbkP",
        "outputId": "21a715f8-036d-4444-ec5d-bc2d33239703"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(example_text['ner_tags']), len(tokenized_input['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkk0aSsMfbPU",
        "outputId": "1243aeac-07b8-4772-826d-efdc642dd787"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        # word_ids() => Return a list mapping the tokens\n",
        "        # to their actual word in the initial sentence.\n",
        "        # It Returns a list indicating the word corresponding to each token.\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        # Special tokens like `` and `<\\s>` are originally mapped to None\n",
        "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # set –100 as the label for these special tokens\n",
        "                label_ids.append(-100)\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # if current word_idx is != prev then its the most regular case\n",
        "                # and add the corresponding token\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                # to take care of sub-words which have the same word_idx\n",
        "                # set -100 as well for them, but only if label_all_tokens == False\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "                # mask the subword representations after the first subword\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "9JkFzB1uf7OM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = tokenize_and_align_lables(data['train'][4:5])\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX0lwCagi146",
        "outputId": "b8c3134f-78cf-4674-95b1-bc7fad2ffe65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So before applying the tokenize_and_align_labels() the tokenized_input has 3 keys\n",
        "- input_ids\n",
        "- token_type_ids\n",
        "- attention_mask\n",
        "But after applying tokenize_and_align_labels() we have an extra key - 'labels'\n",
        "\n",
        "==================================="
      ],
      "metadata": {
        "id": "0QIhllHU1GoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q['input_ids'][0]), q['labels'][0]):\n",
        "  print(f'{token:_<40} {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs_9dR_ijDiv",
        "outputId": "1591109b-7ec9-4db6-f95f-e61b057a4032"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]___________________________________ -100\n",
            "germany_________________________________ 5\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "representative__________________________ 0\n",
            "to______________________________________ 0\n",
            "the_____________________________________ 0\n",
            "european________________________________ 3\n",
            "union___________________________________ 4\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "veterinary______________________________ 0\n",
            "committee_______________________________ 0\n",
            "werner__________________________________ 1\n",
            "z_______________________________________ 2\n",
            "##wing__________________________________ 2\n",
            "##mann__________________________________ 2\n",
            "said____________________________________ 0\n",
            "on______________________________________ 0\n",
            "wednesday_______________________________ 0\n",
            "consumers_______________________________ 0\n",
            "should__________________________________ 0\n",
            "buy_____________________________________ 0\n",
            "sheep___________________________________ 0\n",
            "##me____________________________________ 0\n",
            "##at____________________________________ 0\n",
            "from____________________________________ 0\n",
            "countries_______________________________ 0\n",
            "other___________________________________ 0\n",
            "than____________________________________ 0\n",
            "britain_________________________________ 5\n",
            "until___________________________________ 0\n",
            "the_____________________________________ 0\n",
            "scientific______________________________ 0\n",
            "advice__________________________________ 0\n",
            "was_____________________________________ 0\n",
            "clearer_________________________________ 0\n",
            "._______________________________________ 0\n",
            "[SEP]___________________________________ -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = data.map(tokenize_and_align_lables, batched =True)"
      ],
      "metadata": {
        "id": "nfjw9Hotj5xu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased', num_labels = 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JMfw_6mka1P",
        "outputId": "99ccf3b9-75e3-46a2-dc1b-e629bfc2ba02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Define training args\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "\"test-ner\",\n",
        "evaluation_strategy = \"epoch\",\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=16,\n",
        "per_device_eval_batch_size=16,\n",
        "num_train_epochs=3,\n",
        "weight_decay=0.01,\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "DHvzvrJtkqbs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "hQC2r3jhqSkh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = datasets.load_metric(\"seqeval\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "012c72012d7d428a9d96e35bdad3beb6",
            "ace093a656224d209a75e8e126812ed4",
            "6e821c90f70c4e35902db950cb5ed1dd",
            "2ccebf7f3f9f47ac9ae5c3f34a744452",
            "8ad9b8165a9c4bb4b40f1750d3a61988",
            "bbf813c991684d4ca6a24e4a8a926915",
            "5273f8f00525430d83adefbc8e06a803",
            "0738ae560eb649a8b6ee0eca18b1325e",
            "beeeb85fd68348f593831c1d7636f382",
            "b617ce3fd00e45fd9c8a900840251ed8",
            "b0eda20b8f554d6d9563f08f3428aa88"
          ]
        },
        "id": "1tyg3ka7qdaT",
        "outputId": "d9d5d4cc-da6b-408c-b401-3cc640534fb7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-b144b02b338d>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "012c72012d7d428a9d96e35bdad3beb6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = data['train'][0]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn4tbtKLtwlu",
        "outputId": "5c968d2f-c869-4cc6-9632-e571a9e47c20"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = data[\"train\"].features[\"ner_tags\"].feature.names\n",
        "\n",
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf3P68b-t0LC",
        "outputId": "56759178-c795-415d-f229-1aaf245453c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRelmjygt55R",
        "outputId": "3b0afc10-ca7b-406d-885e-dbdb917adba7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[labels], references=[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYbPs1PTuBG1",
        "outputId": "0933b080-2c5a-4a9a-e3bb-8b7479188388"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
              " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "seqeval - The way the package works by accepting list of lists\n",
        "The seqeval package expects the predictions and labels as lists of lists, with each list corresponding to a single example in our validation or test sets. To integrate these metrics during training, we need a function that can take the outputs of the model and convert them into the lists that seqeval expects.\n",
        "\n",
        "The following does the trick by ensuring we ignore the label IDs associated with subsequent subwords:\n",
        "\n",
        "Compute Metrics\n",
        "This compute_metrics() function first takes the argmax of the logits to convert them to predictions (as usual, the logits and the probabilities are in the same order, so we don’t need to apply the softmax). Then we have to convert both labels and predictions from integers to strings. We remove all the values where the label is -100, then pass the results to the metric.compute() method:"
      ],
      "metadata": {
        "id": "IyeZL3WMuF-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    \"\"\"\n",
        "    Function to compute the evaluation metrics for Named Entity Recognition (NER) tasks.\n",
        "    The function computes precision, recall, F1 score and accuracy.\n",
        "\n",
        "    Parameters:\n",
        "    eval_preds (tuple): A tuple containing the predicted logits and the true labels.\n",
        "\n",
        "    Returns:\n",
        "    A dictionary containing the precision, recall, F1 score and accuracy.\n",
        "    \"\"\"\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we don’t need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "    return {\n",
        "   \"precision\": results[\"overall_precision\"],\n",
        "   \"recall\": results[\"overall_recall\"],\n",
        "   \"f1\": results[\"overall_f1\"],\n",
        "  \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }"
      ],
      "metadata": {
        "id": "pH52AmRzuTXa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**predictions will print a long 2d tensor like below**\n",
        "[['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-LOC', 'O', 'O', 'O', 'O', 'O'], ['B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-ORG', 'O', ['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'B-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'B-ORG', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        ", ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]"
      ],
      "metadata": {
        "id": "8nhBl4nouXhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "   train_dataset=tokenized_dataset[\"train\"],\n",
        "   eval_dataset=tokenized_dataset[\"validation\"],\n",
        "   data_collator=data_collator,\n",
        "   tokenizer=tokenizer,\n",
        "   compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4j21j9Jeuo4n",
        "outputId": "cbc846c4-d4d9-4486-83fd-4d74da7d3d59"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2634/2634 08:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229700</td>\n",
              "      <td>0.062899</td>\n",
              "      <td>0.914098</td>\n",
              "      <td>0.935675</td>\n",
              "      <td>0.924761</td>\n",
              "      <td>0.982207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.045100</td>\n",
              "      <td>0.055807</td>\n",
              "      <td>0.933015</td>\n",
              "      <td>0.941157</td>\n",
              "      <td>0.937068</td>\n",
              "      <td>0.985321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.027200</td>\n",
              "      <td>0.056580</td>\n",
              "      <td>0.936891</td>\n",
              "      <td>0.946638</td>\n",
              "      <td>0.941739</td>\n",
              "      <td>0.985988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2634, training_loss=0.07907758640717989, metrics={'train_runtime': 506.9052, 'train_samples_per_second': 83.098, 'train_steps_per_second': 5.196, 'total_flos': 1024113336121080.0, 'train_loss': 0.07907758640717989, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "U64LjeGsuuMt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6c6SrLDvMYk",
        "outputId": "587e39da-e45a-46ea-c64c-07638e2ba32b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    str(i): label for i,label in enumerate(label_list)\n",
        "}\n",
        "label2id = {\n",
        "    label: str(i) for i,label in enumerate(label_list)\n",
        "}"
      ],
      "metadata": {
        "id": "uI6--zKAvOZS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "fN959CypvQqc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = json.load(open(\"ner_model/config.json\"))"
      ],
      "metadata": {
        "id": "49nAVhzevUW9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"id2label\"] = id2label\n",
        "config[\"label2id\"] = label2id"
      ],
      "metadata": {
        "id": "1mg-DF6DvXCv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(config, open(\"ner_model/config.json\",\"w\"))"
      ],
      "metadata": {
        "id": "EawSaTeDvY2s"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "CQnjrLoSva28"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "oCWtYFAUvc9b"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "example = \"Aman works in Accenture and desire to go to Patna which is in Bihar\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "\n",
        "print(ner_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd-9KAM1vgH6",
        "outputId": "fe75922e-7e2e-4146-9717-90da01e7e90d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-PER', 'score': 0.99809295, 'index': 1, 'word': 'ama', 'start': 0, 'end': 3}, {'entity': 'B-PER', 'score': 0.99795353, 'index': 2, 'word': '##n', 'start': 3, 'end': 4}, {'entity': 'B-ORG', 'score': 0.62788695, 'index': 5, 'word': 'accent', 'start': 14, 'end': 20}, {'entity': 'B-LOC', 'score': 0.80081254, 'index': 6, 'word': '##ure', 'start': 20, 'end': 23}, {'entity': 'B-LOC', 'score': 0.99572194, 'index': 12, 'word': 'patna', 'start': 44, 'end': 49}, {'entity': 'B-LOC', 'score': 0.9965377, 'index': 16, 'word': 'bihar', 'start': 62, 'end': 67}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aB33phsuvlio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}